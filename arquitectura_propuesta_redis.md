# Arquitectura Propuesta con Redis - TrÃ¡nsitoBot Soacha

## ğŸ“‹ InformaciÃ³n General

**VersiÃ³n:** 2.0 (Propuesta con Redis)
**Fecha:** 2025-10-30
**Cambio Principal:** IntegraciÃ³n de Redis para gestiÃ³n de memoria conversacional y contexto

---

## ğŸ¯ Objetivos de la IntegraciÃ³n de Redis

### Problemas Actuales
- âŒ No hay persistencia de historial conversacional entre componentes
- âŒ RASA y BackRag no comparten contexto del usuario
- âŒ Sin cachÃ© de respuestas frecuentes
- âŒ Cada consulta a BackRag es independiente (sin memoria)
- âŒ No hay seguimiento de sesiones de usuario

### Soluciones con Redis
- âœ… **Memoria conversacional persistente** - Historial completo de cada usuario
- âœ… **Contexto compartido** - RASA y BackRag acceden al mismo contexto
- âœ… **CachÃ© inteligente** - Respuestas frecuentes en cache
- âœ… **Sesiones de usuario** - Tracking de estado y metadata
- âœ… **Contexto para LLM** - Claude AI recibe historial relevante
- âœ… **Performance mejorado** - ReducciÃ³n de latencia

---

## ğŸ—ï¸ Arquitectura Propuesta con Redis

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FRONTEND (React + Vite)                   â”‚
â”‚                   http://localhost:5173                      â”‚
â”‚                                                               â”‚
â”‚  - Interfaz conversacional                                   â”‚
â”‚  - Mantiene conversaciÃ³n completa en UI                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â”‚ HTTP/REST + session_id
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ROUTERBACK (FastAPI - Orquestador)              â”‚
â”‚                   http://localhost:8080                      â”‚
â”‚                                                               â”‚
â”‚  NUEVA LÃ“GICA CON REDIS:                                     â”‚
â”‚  1. Recibe mensaje + session_id                              â”‚
â”‚  2. Consulta Redis: obtiene historial conversacional         â”‚
â”‚  3. Enriquece mensaje con contexto                           â”‚
â”‚  4. EnvÃ­a a RASA con contexto                                â”‚
â”‚  5. Si RASA falla â†’ BackRag con contexto completo            â”‚
â”‚  6. Guarda respuesta en Redis                                â”‚
â”‚  7. Actualiza historial conversacional                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                         â”‚        â”‚
           â†“                         â†“        â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
    â”‚   RASA   â”‚            â”‚  BACKRAG   â”‚   â”‚
    â”‚  :5005   â”‚            â”‚   :8000    â”‚   â”‚
    â”‚  :5055   â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚            â”‚
           â”‚                     â”‚            â”‚
           â”‚                     â†“            â”‚
           â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
           â”‚            â”‚   ChromaDB      â”‚   â”‚
           â”‚            â”‚  (192 arts.)    â”‚   â”‚
           â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
           â”‚                     â”‚            â”‚
           â”‚                     â†“            â”‚
           â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
           â”‚            â”‚   Claude AI     â”‚   â”‚
           â”‚            â”‚  (Anthropic)    â”‚   â”‚
           â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
           â”‚                                  â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚         REDIS (Cache Layer)       â”‚
            â”‚        http://localhost:6379      â”‚
            â”‚                                   â”‚
            â”‚  ALMACENA:                        â”‚
            â”‚  â”œâ”€ Historial conversacional      â”‚
            â”‚  â”‚  Key: chat:history:{session}   â”‚
            â”‚  â”‚  Value: [mensaje1, msg2, ...]  â”‚
            â”‚  â”‚                                â”‚
            â”‚  â”œâ”€ Contexto de usuario           â”‚
            â”‚  â”‚  Key: user:context:{session}   â”‚
            â”‚  â”‚  Value: {metadata, state}      â”‚
            â”‚  â”‚                                â”‚
            â”‚  â”œâ”€ Cache de respuestas           â”‚
            â”‚  â”‚  Key: cache:query:{hash}       â”‚
            â”‚  â”‚  Value: {answer, sources}      â”‚
            â”‚  â”‚  TTL: 1 hora                   â”‚
            â”‚  â”‚                                â”‚
            â”‚  â”œâ”€ Sesiones activas              â”‚
            â”‚  â”‚  Key: session:{id}             â”‚
            â”‚  â”‚  Value: {user, created_at}     â”‚
            â”‚  â”‚  TTL: 24 horas                 â”‚
            â”‚  â”‚                                â”‚
            â”‚  â””â”€ Estado de conversaciÃ³n RASA   â”‚
            â”‚     Key: rasa:tracker:{sender}    â”‚
            â”‚     Value: {slots, intent}        â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ Flujos de Datos Actualizados

### Flujo 1: Usuario EnvÃ­a Mensaje (Con Redis)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Usuarioâ”‚
â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
    â”‚
    â”‚ 1. "Â¿CuÃ¡l es la multa por exceso de velocidad?"
    â”‚    + session_id: "abc123"
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Frontend    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”‚ 2. POST /api/v1/chat/message
       â”‚    {session_id, message, metadata}
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              RouterBack                          â”‚
â”‚                                                  â”‚
â”‚  3. Consulta Redis: Historial conversacional    â”‚
â”‚     GET chat:history:abc123                      â”‚
â”‚     â†’ [msg1, msg2, msg3, ...]                    â”‚
â”‚                                                  â”‚
â”‚  4. Enriquece mensaje con contexto:              â”‚
â”‚     - Ãšltimos 5 mensajes                         â”‚
â”‚     - Metadata de usuario                        â”‚
â”‚     - Estado de conversaciÃ³n                     â”‚
â”‚                                                  â”‚
â”‚  5. DecisiÃ³n de routing...                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Â¿RASA?     â”‚
    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”˜
          â”‚   â”‚
    SÃ    â”‚   â”‚  NO (vacÃ­o/error)
          â†“   â†“
       [RASA] [BackRag + Redis]
```

---

### Flujo 2: RASA con Contexto desde Redis

```
RouterBack â†’ Redis: GET user:context:abc123
                   â†’ {name: "Juan", last_intent: "consultar_multas"}

RouterBack â†’ RASA: POST /webhooks/rest/webhook
                   {
                     "sender": "abc123",
                     "message": "Â¿Y cuÃ¡nto cuesta?",
                     "metadata": {
                       "context": {
                         "last_intent": "consultar_multas",
                         "last_entity": "exceso_velocidad"
                       }
                     }
                   }

RASA â†’ RouterBack: [{"text": "La multa tipo C cuesta..."}]

RouterBack â†’ Redis:
  - ZADD chat:history:abc123 timestamp "{role: 'user', msg: 'Â¿Y cuÃ¡nto cuesta?'}"
  - ZADD chat:history:abc123 timestamp "{role: 'bot', msg: 'La multa tipo C...'}"
  - SET user:context:abc123 "{last_intent: 'consultar_multas', ...}" EX 86400

RouterBack â†’ Frontend: Respuesta
```

---

### Flujo 3: BackRag con Memoria Conversacional (LLM Context)

```
RouterBack â†’ Redis: ZRANGE chat:history:abc123 -10 -1
                   â†’ Ãšltimos 10 mensajes de la conversaciÃ³n

RouterBack â†’ BackRag: POST /api/v1/query
                      {
                        "query": "Â¿Y si es en zona escolar?",
                        "conversation_history": [
                          {role: "user", content: "Â¿Multa por exceso?"},
                          {role: "assistant", content: "La multa es..."},
                          {role: "user", content: "Â¿Y si es en zona escolar?"}
                        ],
                        "session_id": "abc123"
                      }

BackRag â†’ Redis: GET cache:query:hash("multa_zona_escolar")
                â†’ MISS (no estÃ¡ en cache)

BackRag â†’ ChromaDB: Vector search con contexto mejorado

BackRag â†’ Claude AI:
  POST /v1/messages
  {
    "system": "Eres un asistente legal...",
    "messages": [
      {"role": "user", "content": "Â¿Multa por exceso?"},
      {"role": "assistant", "content": "La multa es..."},
      {"role": "user", "content": "Â¿Y si es en zona escolar?"}
    ],
    "context": [
      {article: "Art. 131", content: "..."},
      {article: "Art. 132", content: "..."}
    ]
  }

Claude AI â†’ BackRag: Respuesta contextualizada

BackRag â†’ Redis:
  - SET cache:query:hash("multa_zona_escolar") "{answer, sources}" EX 3600
  - Actualizar historial

BackRag â†’ RouterBack â†’ Frontend: Respuesta con contexto
```

---

### Flujo 4: Cache de Respuestas Frecuentes

```
Usuario: "Â¿CuÃ¡l es el nÃºmero de emergencias de trÃ¡nsito?"

RouterBack â†’ Redis: GET cache:query:hash("numero_emergencias_transito")
                   â†’ HIT! {
                       "answer": "El nÃºmero de emergencias es...",
                       "cached_at": "2025-10-30 10:00:00",
                       "ttl": 3500
                     }

RouterBack â†’ Frontend: Respuesta desde cache (< 5ms)
                      + metadata: {from_cache: true}

// No consulta ni RASA ni BackRag - respuesta instantÃ¡nea
```

---

## ğŸ—„ï¸ Estructura de Datos en Redis

### 1. Historial Conversacional (Sorted Set)

**Key:** `chat:history:{session_id}`
**Tipo:** Sorted Set (ordenado por timestamp)
**TTL:** 7 dÃ­as

```redis
ZADD chat:history:abc123 1730300000 '{"role":"user","content":"Hola","timestamp":"2025-10-30T10:00:00Z"}'
ZADD chat:history:abc123 1730300001 '{"role":"assistant","content":"Â¡Hola! Â¿En quÃ© puedo ayudarte?","timestamp":"2025-10-30T10:00:01Z","source":"RASA"}'
ZADD chat:history:abc123 1730300030 '{"role":"user","content":"Â¿Multa por pico y placa?","timestamp":"2025-10-30T10:00:30Z"}'
ZADD chat:history:abc123 1730300032 '{"role":"assistant","content":"SegÃºn el Art. 131...","timestamp":"2025-10-30T10:00:32Z","source":"BackRag"}'

// Obtener Ãºltimos 10 mensajes
ZRANGE chat:history:abc123 -10 -1
```

**Estructura de cada mensaje:**
```json
{
  "role": "user | assistant",
  "content": "texto del mensaje",
  "timestamp": "ISO 8601",
  "source": "RASA | BackRag | cache",
  "metadata": {
    "intent": "consultar_multas",
    "confidence": 0.85,
    "articles_used": ["Art. 131"]
  }
}
```

---

### 2. Contexto de Usuario (Hash)

**Key:** `user:context:{session_id}`
**Tipo:** Hash
**TTL:** 24 horas

```redis
HSET user:context:abc123 last_intent "consultar_multas"
HSET user:context:abc123 last_entity "pico_y_placa"
HSET user:context:abc123 user_location "Soacha"
HSET user:context:abc123 conversation_stage "gathering_info"
HSET user:context:abc123 created_at "2025-10-30T10:00:00Z"
HSET user:context:abc123 last_activity "2025-10-30T10:05:00Z"

// Obtener todo el contexto
HGETALL user:context:abc123
```

**Campos:**
- `last_intent`: Ãšltimo intent detectado por RASA
- `last_entity`: Ãšltima entidad extraÃ­da
- `user_location`: UbicaciÃ³n del usuario (si aplica)
- `conversation_stage`: Etapa de la conversaciÃ³n
- `created_at`: Inicio de sesiÃ³n
- `last_activity`: Ãšltima actividad
- `custom_data`: Metadata adicional (JSON string)

---

### 3. Cache de Respuestas (String con JSON)

**Key:** `cache:query:{query_hash}`
**Tipo:** String (JSON serializado)
**TTL:** 1 hora (ajustable segÃºn frecuencia)

```redis
SET cache:query:5f3a8b2c '{
  "query": "Â¿CuÃ¡l es la multa por exceso de velocidad?",
  "answer": "SegÃºn el ArtÃ­culo 131...",
  "confidence": 0.92,
  "sources": [...],
  "cached_at": "2025-10-30T10:00:00Z",
  "hit_count": 15
}' EX 3600

// Incrementar contador de hits
INCR cache:query:5f3a8b2c:hits
```

**Estrategia de cache:**
- Queries exactas â†’ hash MD5 de la consulta normalizada
- TTL dinÃ¡mico: preguntas frecuentes (24h), otras (1h)
- InvalidaciÃ³n manual si datos cambian

---

### 4. Sesiones Activas (Hash)

**Key:** `session:{session_id}`
**Tipo:** Hash
**TTL:** 24 horas (renovable con actividad)

```redis
HSET session:abc123 user_id "user_123"
HSET session:abc123 channel "web"
HSET session:abc123 created_at "2025-10-30T10:00:00Z"
HSET session:abc123 last_seen "2025-10-30T10:05:00Z"
HSET session:abc123 message_count "12"
HSET session:abc123 device "desktop"

// Renovar TTL con actividad
EXPIRE session:abc123 86400
```

---

### 5. Estado de Tracker RASA (String con JSON)

**Key:** `rasa:tracker:{sender_id}`
**Tipo:** String (JSON)
**TTL:** 24 horas

```redis
SET rasa:tracker:abc123 '{
  "sender_id": "abc123",
  "slots": {
    "tipo_consulta": "multas",
    "tipo_infraccion": "exceso_velocidad"
  },
  "latest_intent": {
    "name": "consultar_multas",
    "confidence": 0.95
  },
  "latest_message": {
    "text": "Â¿CuÃ¡nto cuesta?",
    "intent_ranking": [...]
  },
  "active_loop": null,
  "latest_action_name": "action_consultar_multa"
}' EX 86400
```

---

### 6. Analytics y MÃ©tricas (Counters y Sorted Sets)

```redis
// Contador de consultas por dÃ­a
INCR analytics:queries:2025-10-30

// Queries mÃ¡s frecuentes (por popularidad)
ZINCRBY analytics:popular_queries 1 "multa_exceso_velocidad"

// Latencia promedio
LPUSH analytics:latency:backrag 245
LTRIM analytics:latency:backrag 0 999  // Mantener Ãºltimos 1000

// Rate limiting por usuario
INCR rate_limit:user_123:2025-10-30:10
EXPIRE rate_limit:user_123:2025-10-30:10 3600
```

---

## ğŸ”§ ImplementaciÃ³n TÃ©cnica

### Cambios en RouterBack

**Nuevo archivo:** `routerback/app/core/redis_client.py`

```python
from redis import Redis
from typing import List, Dict, Optional
import json
import hashlib
from datetime import datetime

class RedisManager:
    def __init__(self, host: str = "localhost", port: int = 6379):
        self.redis = Redis(host=host, port=port, decode_responses=True)

    # ===== HISTORIAL CONVERSACIONAL =====

    def add_message_to_history(
        self,
        session_id: str,
        role: str,
        content: str,
        source: str = None,
        metadata: dict = None
    ):
        """Agrega un mensaje al historial conversacional"""
        timestamp = datetime.utcnow().timestamp()
        message = {
            "role": role,
            "content": content,
            "timestamp": datetime.utcnow().isoformat(),
            "source": source,
            "metadata": metadata or {}
        }

        key = f"chat:history:{session_id}"
        self.redis.zadd(key, {json.dumps(message): timestamp})
        self.redis.expire(key, 7 * 24 * 3600)  # 7 dÃ­as

    def get_conversation_history(
        self,
        session_id: str,
        limit: int = 10
    ) -> List[Dict]:
        """Obtiene los Ãºltimos N mensajes de la conversaciÃ³n"""
        key = f"chat:history:{session_id}"
        messages = self.redis.zrange(key, -limit, -1)
        return [json.loads(msg) for msg in messages]

    # ===== CONTEXTO DE USUARIO =====

    def update_user_context(
        self,
        session_id: str,
        context_data: dict
    ):
        """Actualiza el contexto del usuario"""
        key = f"user:context:{session_id}"
        for field, value in context_data.items():
            self.redis.hset(key, field, value)
        self.redis.expire(key, 24 * 3600)  # 24 horas

    def get_user_context(self, session_id: str) -> Dict:
        """Obtiene el contexto completo del usuario"""
        key = f"user:context:{session_id}"
        return self.redis.hgetall(key) or {}

    # ===== CACHE DE RESPUESTAS =====

    def get_cached_response(self, query: str) -> Optional[Dict]:
        """Busca respuesta en cache"""
        query_hash = hashlib.md5(query.lower().strip().encode()).hexdigest()
        key = f"cache:query:{query_hash}"
        cached = self.redis.get(key)

        if cached:
            # Incrementar hit count
            self.redis.incr(f"{key}:hits")
            return json.loads(cached)
        return None

    def cache_response(
        self,
        query: str,
        response: dict,
        ttl: int = 3600
    ):
        """Guarda respuesta en cache"""
        query_hash = hashlib.md5(query.lower().strip().encode()).hexdigest()
        key = f"cache:query:{query_hash}"

        cache_data = {
            **response,
            "cached_at": datetime.utcnow().isoformat(),
            "query": query
        }

        self.redis.setex(key, ttl, json.dumps(cache_data))

    # ===== SESIONES =====

    def create_session(
        self,
        session_id: str,
        user_data: dict
    ):
        """Crea o actualiza una sesiÃ³n"""
        key = f"session:{session_id}"
        session_data = {
            **user_data,
            "created_at": datetime.utcnow().isoformat(),
            "last_seen": datetime.utcnow().isoformat(),
            "message_count": "0"
        }

        for field, value in session_data.items():
            self.redis.hset(key, field, value)
        self.redis.expire(key, 24 * 3600)

    def update_session_activity(self, session_id: str):
        """Actualiza Ãºltima actividad de sesiÃ³n"""
        key = f"session:{session_id}"
        self.redis.hset(key, "last_seen", datetime.utcnow().isoformat())
        self.redis.hincrby(key, "message_count", 1)
        self.redis.expire(key, 24 * 3600)  # Renovar TTL
```

---

**ActualizaciÃ³n:** `routerback/app/api/v1/endpoints/chat.py`

```python
from app.core.redis_client import RedisManager

redis_manager = RedisManager()

@router.post("/message")
async def send_message(user_message: UserMessage):
    session_id = user_message.sender_id

    # 1. Verificar cache primero
    cached_response = redis_manager.get_cached_response(user_message.message)
    if cached_response:
        logger.info(f"[Cache] Respuesta encontrada en cache para: {user_message.message[:50]}")
        return cached_response

    # 2. Obtener historial conversacional
    conversation_history = redis_manager.get_conversation_history(session_id, limit=10)
    user_context = redis_manager.get_user_context(session_id)

    # 3. Guardar mensaje del usuario en historial
    redis_manager.add_message_to_history(
        session_id=session_id,
        role="user",
        content=user_message.message
    )

    # 4. Actualizar actividad de sesiÃ³n
    redis_manager.update_session_activity(session_id)

    # 5. Enviar a RASA con contexto
    rasa_response = await send_to_rasa(
        sender_id=session_id,
        message=user_message.message,
        context=user_context
    )

    if rasa_response:
        # 6a. RASA respondiÃ³
        redis_manager.add_message_to_history(
            session_id=session_id,
            role="assistant",
            content=rasa_response["text"],
            source="RASA"
        )

        # Actualizar contexto con intent detectado
        if "intent" in rasa_response.get("metadata", {}):
            redis_manager.update_user_context(session_id, {
                "last_intent": rasa_response["metadata"]["intent"]
            })

        return rasa_response

    else:
        # 6b. Fallback a BackRag con historial
        backrag_response = await send_to_backrag(
            query=user_message.message,
            conversation_history=conversation_history,
            session_id=session_id
        )

        # Guardar respuesta en historial
        redis_manager.add_message_to_history(
            session_id=session_id,
            role="assistant",
            content=backrag_response["answer"],
            source="BackRag",
            metadata={
                "confidence": backrag_response["confidence"],
                "articles": [s["article"] for s in backrag_response["sources"]]
            }
        )

        # Cache respuestas de alta confianza
        if backrag_response["confidence"] > 0.75:
            redis_manager.cache_response(
                query=user_message.message,
                response=backrag_response,
                ttl=3600  # 1 hora
            )

        return backrag_response
```

---

### Cambios en BackRag

**ActualizaciÃ³n:** `backRag/app/services/llm_service.py`

```python
class LLMService:
    def generate_response(
        self,
        query: str,
        context: List[Dict],
        conversation_history: List[Dict] = None
    ) -> str:
        """
        Genera respuesta usando Claude AI con historial conversacional
        """
        # Construir mensajes con historial
        messages = []

        # Agregar historial si existe
        if conversation_history:
            for msg in conversation_history[-5:]:  # Ãšltimos 5 mensajes
                messages.append({
                    "role": msg["role"],
                    "content": msg["content"]
                })

        # Agregar consulta actual con contexto de artÃ­culos
        context_text = self._format_context(context)
        current_message = f"""
Consulta: {query}

Contexto legal relevante:
{context_text}

Por favor responde basÃ¡ndote en el contexto legal proporcionado.
"""

        messages.append({
            "role": "user",
            "content": current_message
        })

        # Llamar a Claude AI
        response = self.client.messages.create(
            model="claude-3-5-sonnet-20241022",
            max_tokens=1024,
            system="""Eres un asistente legal especializado en el CÃ³digo Nacional
            de TrÃ¡nsito de Colombia. Usa el historial de conversaciÃ³n para dar
            respuestas contextuales y coherentes.""",
            messages=messages
        )

        return response.content[0].text
```

**Nuevo endpoint:** `backRag/app/api/v1/endpoints/query.py`

```python
@router.post("/query")
async def query_transit_code(request: QueryRequest):
    """
    Consulta con soporte para historial conversacional
    """
    # BÃºsqueda en ChromaDB (sin cambios)
    results = search_service.hybrid_search(
        query=request.query,
        max_results=request.max_results
    )

    # Generar respuesta CON historial conversacional
    answer = llm_service.generate_response(
        query=request.query,
        context=results,
        conversation_history=request.conversation_history  # NUEVO
    )

    return QueryResponse(
        answer=answer,
        confidence=confidence_score,
        sources=sources
    )
```

**Actualizar modelo:** `backRag/app/models/query.py`

```python
class QueryRequest(BaseModel):
    query: str
    max_results: int = 3
    confidence_threshold: float = 0.4
    conversation_history: Optional[List[Dict]] = None  # NUEVO
    session_id: Optional[str] = None  # NUEVO
```

---

## ğŸš€ Despliegue de Redis

### OpciÃ³n 1: Docker (Recomendado)

**Nuevo archivo:** `docker-compose.yml`

```yaml
version: '3.8'

services:
  redis:
    image: redis:7-alpine
    container_name: transitobot-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes --maxmemory 512mb --maxmemory-policy allkeys-lru
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 3

volumes:
  redis_data:
    driver: local
```

**Iniciar:**
```bash
docker-compose up -d redis
```

---

### OpciÃ³n 2: InstalaciÃ³n Local

**Ubuntu/Debian:**
```bash
sudo apt update
sudo apt install redis-server
sudo systemctl start redis-server
sudo systemctl enable redis-server
```

**macOS:**
```bash
brew install redis
brew services start redis
```

**Verificar:**
```bash
redis-cli ping
# Respuesta: PONG
```

---

## ğŸ“Š Beneficios de la Arquitectura con Redis

### 1. Memoria Conversacional
- âœ… Respuestas contextuales basadas en conversaciÃ³n previa
- âœ… Usuario puede hacer preguntas de seguimiento
- âœ… "Â¿Y cuÃ¡nto cuesta?" â†’ Entiende que se refiere a la multa anterior

### 2. Contexto Compartido RASA â†” BackRag
- âœ… Si RASA detectÃ³ intent "consultar_multas", BackRag lo sabe
- âœ… BackRag puede continuar la conversaciÃ³n donde RASA la dejÃ³
- âœ… TransiciÃ³n transparente entre sistemas

### 3. Performance
- âœ… Cache de respuestas frecuentes: <5ms vs 500ms
- âœ… ReducciÃ³n de llamadas a Claude AI (ahorro de costos)
- âœ… ReducciÃ³n de carga en ChromaDB

### 4. Escalabilidad
- âœ… Redis puede manejar miles de sesiones concurrentes
- âœ… DistribuciÃ³n de carga entre mÃºltiples instancias
- âœ… Persistencia de datos (RDB + AOF)

### 5. Analytics
- âœ… Tracking de queries mÃ¡s frecuentes
- âœ… AnÃ¡lisis de patrones de conversaciÃ³n
- âœ… MÃ©tricas de satisfacciÃ³n y uso

---

## ğŸ“ˆ Casos de Uso Mejorados

### Caso 1: ConversaciÃ³n con Seguimiento

**Sin Redis:**
```
Usuario: "Â¿CuÃ¡l es la multa por pico y placa?"
Bot: "La multa es de tipo C..."

Usuario: "Â¿Y cuÃ¡nto cuesta?"
Bot: "No entiendo tu consulta" âŒ
```

**Con Redis:**
```
Usuario: "Â¿CuÃ¡l es la multa por pico y placa?"
Bot: "La multa es de tipo C, segÃºn el Art. 131..."
Redis: Guarda contexto {last_query: "pico_placa", last_article: "131"}

Usuario: "Â¿Y cuÃ¡nto cuesta?"
Redis: Recupera contexto â†’ entiende que se refiere a multa tipo C
Bot: "La multa tipo C tiene un valor de..." âœ…
```

---

### Caso 2: Cache de Preguntas Frecuentes

**Pregunta frecuente:** "Â¿CuÃ¡l es el nÃºmero de emergencias?"

**Primera vez:**
- RouterBack â†’ BackRag â†’ ChromaDB â†’ Claude AI
- Tiempo: ~500ms
- Redis: Guarda en cache

**Siguientes veces (prÃ³ximas 24h):**
- RouterBack â†’ Redis (HIT!)
- Tiempo: <5ms
- Ahorro: 99% de latencia, 100% de costo LLM

---

### Caso 3: TransiciÃ³n RASA â†’ BackRag con Contexto

```
Usuario: "Hola"
RASA: "Â¡Hola! Â¿En quÃ© puedo ayudarte?"
Redis: {last_intent: "greet"}

Usuario: "Quiero saber sobre multas"
RASA: "Claro, Â¿quÃ© tipo de multa?"
Redis: {last_intent: "consultar_multas", stage: "gathering_info"}

Usuario: "EspecÃ­ficamente sobre estacionamiento prohibido en zona escolar"
RASA: [] (no tiene respuesta especÃ­fica)
RouterBack â†’ BackRag con contexto:
  - conversation_history: [...]
  - last_intent: "consultar_multas"
  - entity: "estacionamiento_prohibido"

BackRag con Claude AI: Genera respuesta contextual usando:
  - Historial conversacional
  - ArtÃ­culos relevantes de ChromaDB
  - Contexto del intent de RASA

Resultado: Respuesta coherente y contextualizada âœ…
```

---

## ğŸ” Seguridad y Privacidad

### Datos Sensibles
- âŒ No almacenar informaciÃ³n personal (nombres, IDs, etc.)
- âœ… Usar session_id anÃ³nimos
- âœ… TTL cortos (24h) para datos de usuario
- âœ… Encriptar datos sensibles si es necesario

### Rate Limiting
```python
def check_rate_limit(user_id: str, limit: int = 100) -> bool:
    """Limitar a 100 requests por hora"""
    key = f"rate_limit:{user_id}:{datetime.utcnow().strftime('%Y-%m-%d:%H')}"
    current = redis.incr(key)
    redis.expire(key, 3600)
    return current <= limit
```

---

## ğŸ“Š Monitoreo y MÃ©tricas

### Dashboard de Redis
```python
def get_redis_stats():
    return {
        "active_sessions": redis.dbsize(),
        "memory_used": redis.info("memory")["used_memory_human"],
        "cache_hit_rate": calculate_hit_rate(),
        "top_queries": redis.zrange("analytics:popular_queries", 0, 9, desc=True, withscores=True)
    }
```

### Logs Enriquecidos
```
[2025-10-30 10:00:00] [Chat] session=abc123 action=cache_hit query="numero emergencias" latency=3ms
[2025-10-30 10:00:15] [Chat] session=abc123 action=rasa_response source=RASA latency=245ms
[2025-10-30 10:00:30] [Chat] session=abc123 action=backrag_response source=BackRag+Claude latency=1200ms context_used=true
```

---

## ğŸ¯ Resumen de Componentes Actualizados

| Componente | Puerto | Cambios con Redis |
|------------|--------|-------------------|
| Frontend | 5173 | Sin cambios (envÃ­a session_id) |
| RouterBack | 8080 | âœ… IntegraciÃ³n completa con Redis<br>âœ… Cache checking<br>âœ… Historial management<br>âœ… Context sharing |
| RASA | 5005/5055 | âœ… Recibe contexto desde Redis<br>âœ… Guarda tracker en Redis |
| BackRag | 8000 | âœ… Recibe historial conversacional<br>âœ… Genera respuestas contextuales |
| **Redis** | **6379** | **âœ… NUEVO COMPONENTE**<br>âœ… Cache layer<br>âœ… Session store<br>âœ… Conversation memory |
| ChromaDB | - | Sin cambios |
| Claude AI | - | âœ… Recibe historial para contexto |

---

## ğŸš¦ Siguiente Paso: ImplementaciÃ³n

### Fase 1: Setup BÃ¡sico (1-2 dÃ­as)
1. âœ… Instalar Redis (Docker o local)
2. âœ… Crear `redis_client.py` en RouterBack
3. âœ… Implementar funciones bÃ¡sicas (set/get)
4. âœ… Testing de conexiÃ³n

### Fase 2: Historial Conversacional (2-3 dÃ­as)
1. âœ… Implementar almacenamiento de mensajes
2. âœ… Integrar en endpoint `/chat/message`
3. âœ… Pasar historial a BackRag
4. âœ… Testing de conversaciones contextuales

### Fase 3: Cache (1-2 dÃ­as)
1. âœ… Implementar cache de respuestas
2. âœ… Estrategia de invalidaciÃ³n
3. âœ… Testing de hit/miss

### Fase 4: Analytics (1 dÃ­a)
1. âœ… MÃ©tricas bÃ¡sicas
2. âœ… Dashboard simple
3. âœ… Monitoreo

---

**Ãšltima actualizaciÃ³n:** 2025-10-30
**VersiÃ³n:** 2.0 (Propuesta)
**Estado:** ğŸ“‹ Pendiente de implementaciÃ³n
